use std::{collections::HashMap, fmt::Debug, time::Duration};

use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use strum_macros::{Display, EnumDiscriminants, EnumString};
use uuid::Uuid;

use crate::error::Error;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, EnumDiscriminants)]
#[strum_discriminants(name(ExecutionContextKind))]
#[strum_discriminants(derive(Serialize, Deserialize, Hash, Display, EnumString))]
#[strum_discriminants(strum(serialize_all = "snake_case"))]
#[non_exhaustive]
pub enum ExecutionContext {
    LocalProcess(LocalProcessExecutionContext),
    Docker(DockerExecutionContext),
    CloudRun,
}

impl TryFrom<ExecutionContext> for serde_json::Value {
    type Error = Error;

    fn try_from(value: ExecutionContext) -> Result<Self, Self::Error> {
        serde_json::to_value(value).map_err(Error::Serialization)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct LocalProcessExecutionContext {
    /// The command to execute within the process.
    pub entry_point: Vec<String>,
    /// Arguments for the command.
    pub args: Vec<String>,
    /// Environment variables to set within the process.
    pub env_vars: HashMap<String, String>,
    /// Timeout for the execution of the primary command.
    pub exec_timeout: Option<Duration>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct DockerExecutionContext {
    /// The primary command to execute within the provisioned environment.
    pub entry_point: Vec<String>,
    /// Arguments for the command.
    pub args: Vec<String>,
    /// Environment variables to set within the provisioned environment.
    pub env_vars: HashMap<String, String>,
    /// Timeout for the execution of the primary command, in seconds.
    pub exec_timeout: Option<Duration>,
    /// The image to use for the container.
    pub image_uri: String,
    /// Labels or tags to apply to the provisioned resource for tracking.
    pub labels: Option<HashMap<String, String>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WorkerRequest {
    /// The ID of the pipeline this task belongs to.
    pub pipeline_id: Uuid,

    /// The ID of the run this task belongs to.
    pub run_id: Uuid,

    /// The ID of the worker this task should be executed on.
    pub worker_id: Uuid,

    /// The type of resource to provision,
    /// and the type-specific configuration for it.
    pub execution_context: ExecutionContext,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProvisionedWorkerDetails {
    /// A unique identifier for this specific worker instance
    pub worker_id: Uuid,

    /// The platform-specific ID of the worker.
    /// E.g., a Docker container ID, local process PID, Cloud Run Job name.
    pub platform_id: String,

    /// The ID of the ResourceManager implementation that created this.
    pub manager_id: Uuid,

    /// The type of resource that was provisioned (e.g., "docker", "local_process").
    pub resource_type_provisioned: ExecutionContextKind,
    // Information specific to the type of resource, enabling interaction.
    // pub connection_info: ResourceConnectionInfo,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum ProvisionedWorkerStatus {
    Pending,      // Resource is being provisioned.
    Initializing, // Resource is provisioned, but the environment/application inside is starting.
    Running,
    Succeeded,
    Failed,
    Cancelled,
    Terminating,
    Terminated,
    TimedOut,
    Unknown(Option<String>), // Status cannot be determined or an error occurred.
    ErrorState(String),
}

// TODO(thegenem0):
// Maybe split the provisioning and execution into two distinct methods?
// If we want to support speculative execution, we'll need to be able to
// provision a worker, but not actually execute it yet.

/// A trait for Execution Managers.
/// ---
/// An Execution Manager is responsible for provisioning workers and
/// executing tasks on them.
/// Any given Execution Manager is responsible for provisioning resources
/// on a given platform (e.g., Docker, Kubernetes, Cloud Run Jobs).
#[async_trait]
pub trait ExecutionManager: Send + Sync + Debug {
    /// Returns a unique identifier for this specific ExecutionManager instance
    fn manager_id(&self) -> Uuid;

    /// Indicates the type of worker this manager provisions
    /// Used by the Coordinator select an appropriate manager.
    fn supported_resource_type(&self) -> ExecutionContextKind;

    /// This method should return once the worker is provisioned and the task execution has been initiated.
    /// Monitoring the completion of the task is typically done via `get_status`.
    ///
    /// # Returns
    /// Details of the provisioned worker, which includes a `worker_id` generated by the EM.
    async fn provision_and_start_execution(
        &self,
        request: &WorkerRequest,
    ) -> Result<ProvisionedWorkerDetails, Error>;

    /// Fetches the current status of a provisioned worker/task execution.
    /// The `Launcher` will poll this method to determine when a task is complete.
    ///
    /// # Returns
    /// The current `ProvisionedWorkerStatus`.
    async fn get_execution_status(
        &self,
        details: &ProvisionedWorkerDetails,
    ) -> Result<ProvisionedWorkerStatus, Error>;

    /// Fetches abailable logs for an actively executing worker.
    async fn fetch_logs(
        &self,
        details: &ProvisionedWorkerDetails,
        tail_lines: Option<usize>,
    ) -> Result<Vec<String>, Error>;

    /// Attempts to gracefully cancel an ongoing task execution.
    /// This is a best-effort operation.
    ///
    /// # Returns
    /// `Ok(())` if the cancellation request was successfully initiated.
    async fn cancel_execution(&self, details: &ProvisionedWorkerDetails) -> Result<(), Error>;

    /// Tears down/releases a previously provisioned worker and cleans up associated infrastructure.
    /// This should be called after a task is finished (succeeded, failed, cancelled)
    /// or if provisioning failed mid-way.
    ///
    /// # Returns
    /// `Ok(())` if teardown was successful or the worker was already gone/cleaned.
    async fn teardown_worker(&self, details: &ProvisionedWorkerDetails) -> Result<(), Error>;
}
